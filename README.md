# Audio & Music Processing Lab
by Marc Jones, written for Python 3.6+

[Music Information Retrieval (MIR)](https://en.wikipedia.org/wiki/Music_information_retrieval) is a rapidly expanding field of study highlighting the intersections of music and computing. Enclosed in this repository is a compliation of programs that accomplish various MIR-related tasks and excersizes. They were written during my time as a graduate student with the Music Technology Group (MTG) at Pompeu Fabra, and as result many of these notebooks interface with MTG technologies and datasets. Each notebook should provide the necessary tools (or atleast links to said tools) in order to successfully reproduce the work as detailed.

#### Genre Classification with Support Vector Machines & Aritificial Neural Networks
This project undertakes the supervised learning task of musical genre classification. Using a provided dataset of about 440 songs segregated by genre, this project uses audio features extracted with [Essentia](http://essentia.upf.edu/documentation/) and uses a combination of popular data manipulation techniques to preprocess the data for classification. I use SciKit and Keras (with a TensorFlow backend) to implement the classifiers, such as the performance of an SVM and simple NN when handling the preprocessed data. Further each classifier's output accuracy is compared when working with data reduced using Principle Component Analysis (finds max variation between data) vs Linear Discriminate Analysis (finds max variation in data between classes).

#### Acoustic Brainz Duplicates Analysis
[AcousticBrainz (AB)](https://acousticbrainz.org) is an open source database that houses extracted music information data for over [3 million (!!)](https://acousticbrainz.org/statistics-graph) songs. AB does not store the analyzed audio files on its servers due to the vastness of the its library and the copyright complications associated with doing so. Therefore AB relies on a community of enthusiasts to contribute to their database while not having direct access to analyzed audio. Considering that every community members music library is likely to have some overlapping similarities, each song can have many duplicate submissions on the AB database. This program looks over those duplicates to try and identify candidates for having been mislabeled.

#### Comparative BPM Algorithm Analysis
This project undertakes a comparison of state-of-the-art BPM extraction algorithms implmented in Essentia. Using the [GiantSteps Tempo Dataset](https://github.com/GiantSteps/giantsteps-tempo-dataset) from the EU sponsored academic x industrial research project ['GiantSteps'](http://giantsteps-project.eu/#/), we can evaluate the performance of BPM extraction. 


#### Exploring Music with Symbolic Representation
Symbolic representation in a musical context simply refers to the way in which we use symbolism to represent or codify music. Traditionally western music has been represented in musical notation on staffs. On one hand this format has standardized and streamlined the process by which complex pieces of music could be recorded and shared, yet on the other it helped foster an environment in which the understanding of music notation was set aside for an exclusive audience, one with access to the tools and resources to learn this entirely auxiliary language along with its alphabet. With technological advancements in the last couple decades we are no longer limited to this singular portrayal and can instead take multiple symbolic representations of a single piece, looking at them through a variety of lenses. Starting with my own perceptual insights of Debussy’s Clair de Lune I sought to combine a multifaceted approach to understanding the piece. This approach includes global and temporal audio feature extraction, along with midi analysis to help inform my own understanding of Debussy’s masterful work of art.
